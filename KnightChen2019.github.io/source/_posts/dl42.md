---
title: 这！就是深度学习之卷积神经网络（四十二）
top: false
cover: false
toc: true
mathjax: true
date: 2019-09-08 17:20:58
password:
summary: 风景旧曾谙。能不忆江南？
tags:
  - 卷积神经网络
  - CNN
categories: 深度学习
---
卷积神经网络（Convolutional  Neural Network，CNN）是一种专门用来处理具有类似网格结构的数据的神经网络，例如时间序列数据（可以认为是在时间轴上有规律地采样形成的一维网格）和图像数据（可以看作二维的像素网格）。

这里引用cs231n课程里的一副CNN的图片：

![卷积神经网络](dl4201.jpg)

上面图片的意思是给定一张图片，利用卷积神经网络来判断它是汽车，卡车，飞机，轮船还是马。之前说过神经网络有输入层，隐藏层，输出层，卷积神经网络则把隐藏层做了更细致的划分，并且加深了神经网络的深度，即层数。根据上图，可以看到它包括CONV（卷积层），RELU（激励层），POOL（池化层），FC（全连接层），我们接下来看看这些层到底是干啥用的。

#### CONV（卷积层）

这也是卷积神经网络中卷积的来源。卷积是一种运算，它是输入矩阵某一块和卷积核（或者叫滤波器，filter）的点积。这里引用吴恩达老师深度学习中的一张图：

![卷积运算](dl4202.png)

一个6\*6的矩阵，和一个3\*3的filter做卷积运算，得到一个实数，填充到一个4\*4的输出矩阵的左上角，这个绿色框框中的值就是：
$$
3 \times 1 + 0 \times 0 + 1 \times -1 + 1 \times 1 + 5 \times 0 + 8 \times -1 + 2 \times 1 + 7 \times 0 + 2 \times -1 = -5
$$
然后这个filter接着往右移动，一次移动1格，移到头了，接着再从最左边往下移动1格，然后再往右移动，简单来说，就是从左往右，从上到下。填充完毕的结果如下图：

![卷积运算结果](dl4203.png)



**这个时候，你可能会有一个疑问，4\*4的矩阵是怎么来的？**

这里有一个公式：
$$
out = \frac {input - filter} {stride} +1
$$
上面的式子中，input表示输入层的大小，filter表示卷积核的大小，stride表示步长，就是一次移动多少步，对于上面的例子有：
$$
out = \frac {6-3} {1} + 1 = 4
$$
所以，我们得到了4\*4的输出矩阵。

**这个时候，你可能还有个疑问，如果$\frac {input - filter} {stride}$不是整数怎么办？**

我们一般会上取整，也就是不管1.XXX...，我们只取1。

当然还有一种更常见的做法是在输入矩阵的周围加上padding，如下图所示：

![Padding](dl4204.png)

padding的值可以全为0，也可以和周边元素的值相同。这个时候，输出矩阵的大小就变成了：
$$
out = \frac {input - filter +2 \times padding} {stride} +1
$$

#### RELU（激励层）

激励层就是用激活函数ReLU作用在输出矩阵的输出，你如果还记得ReLU函数：

![激活函数ReLU](dl4205.jpg)

可以看到当自变量<0, 因变量=0，所以它的收敛速度比较快，求梯度的速度也比较快。



#### POOL（池化层）

池化层也可以看作是输入矩阵和滤波器的一种运算，只不过这种运算不是点积，而是取当前窗口矩阵中所有元素的最大值或者平均值，如下图所示：

![Pool](dl4206.jpg)

因为只是取了一个值，所以它可以减少数据的空间尺寸。池化层之所有有效，是因为图片特征的不变性，也就是通过下采样不会丢失图片所拥有的特征，由于这种特性，我们可以将图片缩小再进行卷积处理，从而大大降低卷积运算的时间。



#### FC（全连接层）

全连接层和前面说过的神经网络模型是一样的，每个神经元与前一层所有的神经元全部链接。这个过程中为了防止过拟合会引入dropout，即随机丢掉一些神经元之间的连接。



#### 经典的神经网络结构

##### LeNet-5

CNN之父Lecun在1988年发明，用来识别手写数字。先来看看LeNet-5的网络结构：

![LeNet-5](dl4207.png)

LeNet-5是针对灰度图片训练的，所有输入只有一个通道，假设你想识别上面的字母A，实际的图片大小就是$32 \times 32 \times 1$，使用6个$5 \times 5$，并且步幅为1的过滤器，那么输出就是$28 \times 28 \times 6$（其中$28=\frac{32-5}{1}+1$）,图像尺寸就从$32 \times 32$缩小到了$28 \times 28$。

然后进行池化操作，平均池化，过滤器的宽度为2，步幅为2，宽度和高度都缩小了2倍，输出结果是一个

$14 \times 14 \times 6$（其中$14=\frac{28-2}{2}+1$）的图像。

接下来使用16个$5 \times 5$，并且步幅为1的过滤器，新的输出结果有16个通道，输出图像大小为$10 \times 10 \times 16$（其中$10=\frac{14-5}{1}+1$）。

继续进行池化操作，宽高又缩小2倍，输出一个$5 \times 5 \times 16$的图像。将所有的数字相乘，得到400个节点。

下一层是全连接层，有400个节点，每一个节点有120个神经元。但有时还会从这400个节点中抽取一部分构建另外一个全连接层，如上图的C5和F6。

最后就是利用这84个特征得到最后的输出。我们可以再加一个节点用来预测$\hat y$的值，$\hat y$有10个可能的值，用来识别对应的输出。

从上图可以看出，随着网络越来越深，图像在变小，但是通道数在增加。



##### AlexNet

它是Alex Krizhevsky发明的，另外两位合著者是IIya Sutskever和Geoffery Hinton, 并且在2012的ImageNet拿了冠军，它的网络结构如下：

![AlexNet](dl4208.png)

AlexNet首先使用一张$227 \times 227 \times 3$的图片作为输入，这里的乘以3是因为彩色图片可以用R，G，B三原色来表示，所以有3个输入通道。

第一层使用96组$11 \times 11$的过滤器，步幅为4，图片输出为$55 \times 55$（其中$55=\frac{227-11}{4}+1$），缩小了4倍左右。

第二层使用一个$3 \times 3$的过滤器构建最大池化层，步幅s=2，卷积层图像缩小为$27 \times 27 \times 96$（其中$27=\frac{55-3}{2}+1$）

接着执行一个$5 \times 5$的卷积，padding之后，输出为$27 \times 27 \times 256$（其中$27=\frac{27-5+1\times2}{1}+1$）,图像大小没有变，但是通道数增加了不少。

接着进行最大池化，过滤器为$3 \times 3$，步幅为2，图像缩小为到$13 \times 13 \times 256$（其中$13=\frac{27-2}{2}+1$）。

再进行一次$3 \times 3$的same卷积，经过padding之后，输出为$13 \times 13 \times 384$。

再做一次same卷积，输出为$13 \times 13 \times 384$。

再做一次same卷积，输出为$13 \times 13 \times 256$。

接着做一次最大池化操作，过滤器为$3 \times 3 $，步幅为2，得到输出为$6 \times 6 \times 256$（其中$6=\frac{13-3}{2}+1$）。

将其展开为9216（$6 \times 6 \times 256$）个单元，然后就是全连接层，dropout一些连接，得到4096个单元，再dropout一些连接，最后得到1000个输出单元。

最后使用softmax函数输出识别的结果，看它究竟是1000个可能对象中的哪一个。

AlexNet比LeNet表现更出色的另一个原因是它使用了ReLU激活函数。



##### VGG Network

它是牛津大学VGG实验室设计的架构，将AlexNet的8层提高到了19层，真正的体现了深度这个词的含义，这里我们介绍一下VGG-16，顾名思义，它有16层，它的网络结构如下：

![VGG Network](dl4209.png)

比如要识别一个$224 \times 224 \times 3$的图像，在最开始的两层使用64个$3\times3$的过滤器，输出结果为$224 \times 224 \times 64$，接着创建一个池化层，将输入图像进行压缩，从$224 \times 224 \times 64$减少到$112 \times 112 \times 64$。然后又是若干个卷积层，使用129个滤波器，以及一些same卷积，输出图像大小为$112 \times 112 \times 128$，接着进行池化，最后输出图像为$56 \times 56 \times 128$，以此类推，最后将得到的$7 \times 7 \times 512$的特征图进行全连接，得到4096个单元，最后进行softmax激活，输出从1000个对象中识别的结果，过程图如下：

![VGG-16](dl4210.png)



VGG大量的使用$3 \times 3$ 的卷积层，这一特点大大的简化了神经网络结构。



##### GoogLeNet

它是谷歌实验室设计的架构，它的结构如下：

![GoogleNet](dl4211.jpg)

它把网络的深度扩展为22层，大量的使用了Inception，并且经历了4个版本的inception。

###### Inception v1

老版本的Inception v1结构如下：

![Old Inception v1](dl4212.png)

如上图所示，初始版本的Inception v1，通过设计一个稀疏网络结构，从而产生稠密的数据。该结构将CNN中常用的卷积（1x1，3x3，5x5）和池化操作（3x3）堆叠在一起，一方面增加了网络的width，另一方面增加了网络对尺度的适应性。

该版本中所有的卷积核都在上一层的输出中进行，而5x5的卷积核需要的计算量比较到，造成了特征图的厚度很大，为了避免这种情况，在3x3和5x5前，max pooling之后分别加上了1x1的卷积核，从而降低特征图厚度，新的Inception v1结构如下：

![New Inception v1](dl4213.jpg)



###### Inception v2

大尺寸的卷积核可以带来更大的感受野，但也会产生更多的参数，比如5x5卷积核的参数为25个，但是3x3卷积核的参数只有9个，所以GooLeNet团队提出用2个连续的3x3卷积层组成小网络来代替单个的5x5卷积层。

通过大量的实验表明，这种分解不会造成表达缺失。那么还能不能分解的更小一点呢，答案是可以的，任意的nxn的卷积都可以通过1xn卷积后接nx1卷积来代替，如下图所示：

![Inception v2](dl4214.jpg)



###### Inception v3

v3一个最重要的改进是分解（Factorization），将7x7分解成两个一维的卷积（1x7,7x1），3x3也是一样（1x3,3x1），这样的好处，既可以加速计算（多余的计算能力可以用来加深网络），又可以将1个conv拆成2个conv，使得网络深度进一步增加，增加了网络的非线性，还有值得注意的地方是网络输入从224x224变为了299x299，更加精细设计了35x35/17x17/8x8的模块。



###### Inception v4

随着神经网络的深度加深，梯度消失的可能性也越大。 Inception v4研究了Inception模块与残差连接（Residual Connection）的结合。

该结构如下图所示：

![Inception v4](dl4215.jpg)

通过20个类似的模块组合，从而大大的加深了网络深度，还极大的提升了训练速度，同时性能也有提升。

